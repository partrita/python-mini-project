import pandas as pd
import requests
from bs4 import BeautifulSoup

base_url = "https://www.flipkart.com/mobiles/pr?sid=tyy%2C4io&otracker=categorytree&p%5B%5D=facets.brand%255B%255D%3DAPPLE&page="


def mobile_name(doc_new):
    prase = doc_new.find_all("div", class_="_4rR01T")
    names = []
    for tag in prase:
        names.append(tag.text.strip())
    return names


def prices(doc_new):
    price = doc_new.find_all("div", class_="_30jeq3 _1_WHN1")
    price_link = []
    for i in price:
        price_link.append(i.text.strip())
    return price_link


def percentage_off(doc_new):
    off = doc_new.find_all("div", class_="_3Ay6Sb")
    off_link = []
    for i in off:
        off_link.append({"Percentage off": i.text.strip()})
    return off_link


def rating(doc_new):
    ratings = doc_new.find_all("div", class_="_3LWZlK")
    all_ratings = []
    for i in ratings:
        all_ratings.append(i.text.strip())
    return all_ratings


def mobile_description(doc_new):
    mobile_description = doc_new.find_all("ul", class_="_1xgFaf")
    mobile_info_link = []
    for i in mobile_description:
        mobile_info_link.append(i.text.strip())
    return mobile_info_link


def for_all_pages(page_no):
    page_no_url = base_url + str(page_no)
    response = requests.get(page_no_url)

    if response.status_code != 200:
        print("Status code:", response.status_code)
        raise Exception("Failed to fetch web page " + page_no_url)

    doc_new = BeautifulSoup(response.text)
    mobile_names_new = mobile_name(doc_new)
    all_prices_new = prices(doc_new)
    all_ratings_new = rating(doc_new)
    first_page_new = mobile_description(doc_new)
    data_new = {
        "Name": mobile_names_new,  # getting all the information in a dictionary
        "Prices": all_prices_new,
        "ratings": all_ratings_new,
        "Description": first_page_new,
    }

    return pd.DataFrame(data_new)  # return directly a dataframe.


# Below is our helper function to add all data frames.


def all_info(num_of_page):
    # define an empty list
    all_df = []
    # Run a loop from 1 to n+1
    for i in range(1, num_of_page + 1):
        all_df.append(for_all_pages(page_no=i))
        # Outside the loop variable you can directly merge the df and return it in the same line.
        merge = pd.concat(all_df)
        csv = merge.to_csv("all info.csv", index=None)
    return csv
